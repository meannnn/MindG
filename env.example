# ============================================================================
# MINDPHASE ENVIRONMENT CONFIGURATION
# ============================================================================
# Copy this file to .env and configure according to your deployment needs

# ============================================================================
# APPLICATION CONFIGURATION
# ============================================================================
HOST=0.0.0.0
PORT=9527
DEBUG=False

# Optional: Set your public WAN IP for external access (auto-detected if not set)
# EXTERNAL_HOST=your-public-ip-address

# Optional: Full base URL for external access (takes precedence over EXTERNAL_HOST)
# Use this when behind a reverse proxy with HTTPS (e.g. Nginx Proxy Manager)
# Example: https://your-domain.com (no trailing slash)
# EXTERNAL_BASE_URL=https://your-domain.com

# ============================================================================
# LLM MODELS CONFIGURATION
# ============================================================================

QWEN_API_KEY=your-qwen-api-key-here
QWEN_API_URL=https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions
QWEN_MODEL_CLASSIFICATION=qwen-plus-latest
QWEN_MODEL_GENERATION=qwen-plus-latest

DASHSCOPE_QPM_LIMIT=13500
DASHSCOPE_CONCURRENT_LIMIT=500
DASHSCOPE_RATE_LIMITING_ENABLED=false

ARK_API_KEY=your-ark-api-key-here
ARK_BASE_URL=https://ark.cn-beijing.volces.com/api/v3
ARK_DEEPSEEK_ENDPOINT=ep-20250101000000-dummy
ARK_KIMI_ENDPOINT=ep-20250101000000-dummy
ARK_DOUBAO_ENDPOINT=ep-20250101000000-dummy

# Volcengine ARK Rate Limiting (Endpoint-Specific)
# Each endpoint has independent limits per Volcengine provider
# Official limits:
#   - ark-deepseek (v3.2): 15,000 RPM, 1,500,000 TPM
#   - ark-kimi: 5,000 RPM, 500,000 TPM
#   - ark-doubao: 30,000 RPM, 5,000,000 TPM
# Note: Each endpoint is tracked separately with endpoint-specific Redis keys
KIMI_VOLCENGINE_QPM_LIMIT=4500
KIMI_VOLCENGINE_CONCURRENT_LIMIT=500
DOUBAO_VOLCENGINE_QPM_LIMIT=27000
DOUBAO_VOLCENGINE_CONCURRENT_LIMIT=500

# Legacy ARK rate limiting (deprecated - use endpoint-specific limits above)
ARK_QPM_LIMIT=4500
ARK_CONCURRENT_LIMIT=500
ARK_RATE_LIMITING_ENABLED=false

# Load Balancing Rate Limiting (for DeepSeek)
# DeepSeek is load-balanced between Dashscope and Volcengine
# Official Dashscope limits:
#   - deepseek-v3.1: 15,000 RPM, 1,200,000 TPM
#   - deepseek-v3.2: 15,000 RPM, 1,500,000 TPM
#   - deepseek-r1: 15,000 RPM, 1,200,000 TPM
# Volcengine ark-deepseek endpoint (v3.2): 15,000 RPM, 1,500,000 TPM (same as Dashscope)
LOAD_BALANCING_RATE_LIMITING_ENABLED=true

# DeepSeek Dashscope Route Rate Limits
# DEPRECATED: DeepSeek Dashscope route now uses shared DASHSCOPE_QPM_LIMIT (same as Qwen)
# This is because all Dashscope traffic (Qwen + DeepSeek Dashscope route) counts as one combined limit
# These settings are kept for backward compatibility but are NOT USED
# The shared Dashscope rate limiter handles both Qwen and DeepSeek Dashscope routes together
DEEPSEEK_DASHSCOPE_QPM_LIMIT=13500
DEEPSEEK_DASHSCOPE_CONCURRENT_LIMIT=500

# DeepSeek Volcengine Route Rate Limits
# These limits are used for the Volcengine route (ark-deepseek endpoint)
# Separate from Dashscope limits since Volcengine is a different provider
DEEPSEEK_VOLCENGINE_QPM_LIMIT=13500
DEEPSEEK_VOLCENGINE_CONCURRENT_LIMIT=500

HUNYUAN_API_KEY=your-hunyuan-secretkey-here
HUNYUAN_SECRET_ID=your-hunyuan-secretid-here
HUNYUAN_API_URL=https://hunyuan.tencentcloudapi.com
HUNYUAN_MODEL=hunyuan-turbo
DASHSCOPE_QPM_LIMIT=10000
DASHSCOPE_CONCURRENT_LIMIT=500
DASHSCOPE_RATE_LIMITING_ENABLED=false

ARK_API_KEY=your-ark-api-key-here
ARK_BASE_URL=https://ark.cn-beijing.volces.com/api/v3

ARK_DEEPSEEK_ENDPOINT=ep-20250101000000-dummy
ARK_KIMI_ENDPOINT=ep-20250101000000-dummy
ARK_DOUBAO_ENDPOINT=ep-20250101000000-dummy

# Rate Limiting (Optional)
ARK_QPM_LIMIT=5000
ARK_CONCURRENT_LIMIT=500
ARK_RATE_LIMITING_ENABLED=false

HUNYUAN_API_KEY=your-hunyuan-secretkey-here
HUNYUAN_SECRET_ID=your-hunyuan-secretid-here
HUNYUAN_API_URL=https://hunyuan.tencentcloudapi.com
HUNYUAN_MODEL=hunyuan-turbo

# ============================================================================
# LOAD BALANCING CONFIGURATION
# ============================================================================
# Distributes DeepSeek requests between Dashscope and Volcengine
# Only DeepSeek is load-balanced; Qwen always uses Dashscope; Kimi/Doubao always use Volcengine

LOAD_BALANCING_ENABLED=true
LOAD_BALANCING_STRATEGY=round_robin
LOAD_BALANCING_WEIGHTS=dashscope:50,volcengine:50

# ============================================================================
# UI & DISPLAY CONFIGURATION
# ============================================================================
GRAPH_LANGUAGE=zh
DEFAULT_LANGUAGE=zh
TOPIC_FONT_SIZE=18
CHAR_FONT_SIZE=14
WATERMARK_TEXT=MindGraph

# ============================================================================
# LOGGING & DEBUGGING
# ============================================================================
LOG_LEVEL=INFO
VERBOSE_LOGGING=False

# ============================================================================
# FEATURE FLAGS
# ============================================================================
# Core Features
FEATURE_MINDMATE=False
FEATURE_VOICE_AGENT=False
FEATURE_DRAG_AND_DROP=False
FEATURE_TAB_MODE=False
FEATURE_IME_AUTOCOMPLETE=False

# Sidebar Features
FEATURE_COURSE=False                    # Thinking Course (思维课程) - Disabled by default
FEATURE_TEMPLATE=False                  # Template Resources (模板资源) - Disabled by default
FEATURE_COMMUNITY=False                 # Community Sharing (社区分享) - Disabled by default
FEATURE_ASKONCE=True                    # AskOnce (多应) - Multi-LLM chat - Enabled by default
FEATURE_SCHOOL_ZONE=False               # School Zone (学校专区) - Organization sharing - Disabled by default
FEATURE_DEBATEVERSE=False               # DebateVerse (论境) - US-style debate system - Disabled by default
FEATURE_KNOWLEDGE_SPACE=False           # Personal Knowledge Space (RAG) - Disabled by default (requires Qdrant and Celery)
FEATURE_LIBRARY=False                   # Library (图书馆) - PDF viewing with danmaku comments - Disabled by default
FEATURE_RAG_CHUNK_TEST=False            # RAG Chunk Test - Disabled by default
FEATURE_SMART_RESPONSE=False            # Smart Response (智回) - ESP32 watch teacher interface - Disabled by default
FEATURE_TEACHER_USAGE=False             # Teacher Usage (教师使用度) - Admin analytics dashboard - Disabled by default

# ============================================================================
# AI ASSISTANT CONFIGURATION
# ============================================================================
DIFY_API_KEY=your_dify_api_key_here
DIFY_API_URL=https://api.dify.ai/v1
DIFY_TIMEOUT=30
AI_ASSISTANT_NAME=教学设计

# ============================================================================
# GEWE WECHAT INTEGRATION CONFIGURATION (Admin Only)
# ============================================================================
GEWE_TOKEN=your_gewe_token_here
GEWE_BASE_URL=http://api.geweapi.com
GEWE_TIMEOUT=30

# Gewe Webhook Security Configuration
# IP Whitelisting: Comma-separated list of allowed IP addresses for webhook requests
# Leave empty to allow all IPs (dev mode). In production, add Gewe API server IPs.
# Example: GEWE_WEBHOOK_ALLOWED_IPS=82.157.39.177,123.45.67.89
GEWE_WEBHOOK_ALLOWED_IPS=

# Default webhook callback URL for reference
# Note: Currently uses main application port (9527). For production, consider using
# a separate port for webhooks (like xxxbot pattern) for better isolation and security.
# Example: http://123.45.67.89:9527/api/gewe/webhook
# Alternative (separate port): http://123.45.67.89:9528/api/gewe/webhook

# ============================================================================
# DATABASE CONFIGURATION
# ============================================================================
# PostgreSQL (default after migration)
# Format: postgresql://user:password@host:port/database
# 
# DEFAULT VALUES (used by migration script if not set):
# - User: mindgraph_user
# - Password: mindgraph_password
# - Host: localhost
# - Port: 5432
# - Database: mindgraph
#
# The migration script (scripts/migrate_sqlite_to_postgresql.py) will use
# these defaults if DATABASE_URL is not set or if individual POSTGRESQL_*
# environment variables are not set.
DATABASE_URL=postgresql://mindgraph_user:mindgraph_password@localhost:5432/mindgraph

# SQLite (legacy - only used during migration from SQLite to PostgreSQL)
# Uncomment below to use SQLite temporarily (migration will run automatically)
# DATABASE_URL=sqlite:///./data/mindgraph.db

# PostgreSQL Subprocess Management (Option B - Primary)
# Application manages PostgreSQL as subprocess (like Qdrant/Celery)
# Set POSTGRESQL_MANAGED_BY_APP=false to use external/systemd PostgreSQL service
POSTGRESQL_MANAGED_BY_APP=true

# PostgreSQL Data Directory (for subprocess mode)
# Directory where PostgreSQL will store its data files
# Will be created automatically if it doesn't exist
# 
# Automatic path selection (if not set):
# - WSL: Uses ~/.mindgraph/postgresql (Linux-native path)
# - Ubuntu/Debian (as root with /root/ path): Uses /var/lib/postgresql/mindgraph
# - Otherwise: Uses ./storage/postgresql (relative to project root)
POSTGRESQL_DATA_DIR=./storage/postgresql

# PostgreSQL Connection Settings
# These settings are used when POSTGRESQL_MANAGED_BY_APP=true
# They must match the values in DATABASE_URL above
# 
# DEFAULT VALUES (used by migration script if not set):
# These are the default credentials that will be used if not specified.
# The migration script will use these values when constructing the connection URL.
POSTGRESQL_PORT=5432
POSTGRESQL_USER=mindgraph_user
POSTGRESQL_PASSWORD=mindgraph_password
POSTGRESQL_DATABASE=mindgraph

# Database Connection Pool Configuration
# PostgreSQL defaults: pool_size=30, max_overflow=60 (for 6 workers)
# Adjust based on your worker count: pool_size = workers * 5
# DATABASE_POOL_SIZE=30
# DATABASE_MAX_OVERFLOW=60
# DATABASE_POOL_TIMEOUT=60

# Database Integrity Check Configuration (PostgreSQL)
# PostgreSQL uses connection tests instead of PRAGMA commands
# Health checks use simple SELECT 1 queries
DB_QUICK_CHECK_ENABLED=true

# ============================================================================
# TOKEN TRACKING CONFIGURATION
# ============================================================================
TOKEN_TRACKER_ENABLED=true
TOKEN_TRACKER_BATCH_SIZE=1000
TOKEN_TRACKER_BATCH_INTERVAL=300
TOKEN_TRACKER_MAX_BUFFER_SIZE=10000

# ============================================================================
# DIAGRAM STORAGE CONFIGURATION
# ============================================================================
# Persistent storage for user diagrams with Redis caching
DIAGRAM_CACHE_TTL=604800
DIAGRAM_SYNC_INTERVAL=300
DIAGRAM_SYNC_BATCH_SIZE=100
DIAGRAM_MAX_PER_USER=20
DIAGRAM_MAX_SPEC_SIZE_KB=500

# ============================================================================
# DATABASE BACKUP CONFIGURATION
# ============================================================================
BACKUP_ENABLED=true
BACKUP_HOUR=3
BACKUP_RETENTION_COUNT=2
BACKUP_DIR=backup

# ============================================================================
# TENCENT CLOUD OBJECT STORAGE (COS) CONFIGURATION (Optional)
# ============================================================================
# Register at: https://console.cloud.tencent.com/cos5
COS_BACKUP_ENABLED=false
COS_BUCKET=your-bucket-name-appid
COS_REGION=ap-beijing
COS_KEY_PREFIX=backups/mindgraph-CHANGE

# ============================================================================
# AUTHENTICATION & SECURITY CONFIGURATION
# ============================================================================
# NOTE: JWT_SECRET_KEY is no longer needed in .env
# It is auto-generated and stored in Redis for multi-worker safety
# Users only need to re-login if Redis is flushed (rare event)

JWT_EXPIRY_HOURS=24

# Maximum concurrent sessions per user (default: 2 devices)
# When exceeded, oldest sessions are automatically logged out
MAX_CONCURRENT_SESSIONS=2

# Auth modes: standard, enterprise, demo, bayi
AUTH_MODE=standard
# Admin phone numbers (comma-separated)
# ADMIN_PHONES=13812345678,13987654321
ADMIN_PHONES=

# Enterprise Mode (only if AUTH_MODE=enterprise)
ENTERPRISE_DEFAULT_ORG_CODE=DEMO-001
ENTERPRISE_DEFAULT_USER_PHONE=enterprise@system.com

# Demo Mode (only if AUTH_MODE=demo)
DEMO_PASSKEY=888888
ADMIN_DEMO_PASSKEY=999999

# Public Dashboard (passkey-protected public dashboard)
PUBLIC_DASHBOARD_PASSKEY=123456

# Dashboard Configuration
DASHBOARD_MAX_CONCURRENT_SSE_CONNECTIONS=2
DASHBOARD_SSE_POLL_INTERVAL_SECONDS=5
DASHBOARD_STATS_UPDATE_INTERVAL=10
DASHBOARD_HEARTBEAT_INTERVAL=30
DASHBOARD_STATS_CACHE_TTL=3
DASHBOARD_MAP_DATA_CACHE_TTL=20
DASHBOARD_REGISTERED_USERS_CACHE_TTL=300
DASHBOARD_TOKEN_USAGE_CACHE_TTL=60

# Bayi Mode (only if AUTH_MODE=bayi)
BAYI_DECRYPTION_KEY=v8IT7XujLPsM7FYuDPRhPtZk
BAYI_DEFAULT_ORG_CODE=BAYI-001
BAYI_CLOCK_SKEW_TOLERANCE=10
BAYI_IP_WHITELIST=

# Invitation Codes: Format AAAA-XXXXX
# Internal format: ORG_CODE:INVITATION_CODE:EXPIRY_DATE
INVITATION_CODES=DEMO-001:DEMO-A1B2C:never

# ============================================================================
# TENCENT CLOUD SMS CONFIGURATION (Optional)
# ============================================================================
# Register at: https://console.cloud.tencent.com/smsv2
TENCENT_SMS_SECRET_ID=your-tencent-secret-id-here
TENCENT_SMS_SECRET_KEY=your-tencent-secret-key-here
TENCENT_SMS_SDK_APP_ID=1400000000
TENCENT_SMS_SIGN_NAME=MindGraph
TENCENT_SMS_REGION=ap-guangzhou
TENCENT_SMS_TEMPLATE_REGISTER=1234567
TENCENT_SMS_TEMPLATE_LOGIN=1234568
TENCENT_SMS_TEMPLATE_RESET_PASSWORD=1234569
TENCENT_SMS_TEMPLATE_ALERT=12345678
TENCENT_SMS_TEMPLATE_STARTUP=123456

SMS_CODE_EXPIRY_MINUTES=5
SMS_RESEND_INTERVAL_SECONDS=60
SMS_MAX_ATTEMPTS_PER_PHONE=5
SMS_MAX_ATTEMPTS_WINDOW_HOURS=1
SMS_MAX_CONCURRENT_REQUESTS=10
SMS_QPM_LIMIT=100
SMS_RATE_LIMITING_ENABLED=true
SMS_STARTUP_NOTIFICATION_ENABLED=true

# ============================================================================
# REDIS CONFIGURATION (REQUIRED)
# ============================================================================
# MindGraph uses PostgreSQL + Redis architecture
# Redis is REQUIRED. Application will NOT start without Redis.
#
# To enable Redis authentication (Ubuntu):
#   1. sudo nano /etc/redis/redis.conf
#   2. Find "# requirepass foobared" and change to: requirepass your-secure-redis-password
#   3. sudo systemctl restart redis-server
#   4. Update REDIS_URL below with: redis://:your-secure-redis-password@localhost:6379/0
#
# Format: redis://[:password]@host:port/db
# Examples:
#   Without password: redis://localhost:6379/0
#   With password:    redis://:your-secure-redis-password@localhost:6379/0
#   Remote server:    redis://:password@redis.example.com:6379/0

REDIS_URL=redis://localhost:6379/0

# Redis connection settings (used by Celery and other services)
# Default Redis host and port (used if REDIS_URL is not set or for Celery)
REDIS_HOST=localhost
REDIS_PORT=6379

# Connection pool settings (optional)
# REDIS_MAX_CONNECTIONS=50
# REDIS_SOCKET_TIMEOUT=5

# User Auth Cache Preloading
# Pre-loads all users and organizations from database into Redis cache at startup
# Set to false to skip preloading (useful for development to speed up startup)
# Cache will still be populated on-demand when users access the system
PRELOAD_USER_AUTH_CACHE=true

# ============================================================================
# CELERY CONFIGURATION (REQUIRED)
# ============================================================================
# Celery is REQUIRED for background task processing (document processing, etc.)
# Application will NOT start without Celery worker.
#
# Celery uses Redis as broker and result backend.
# Default configuration uses Redis DB 1 for Celery (DB 0 is used for caching).
#
# Start Celery worker:
#   celery -A config.celery worker --loglevel=info
#
# Or use the server launcher which starts Celery automatically:
#   python main.py

# Redis database number for Celery (default: 1, DB 0 is used for application cache)
REDIS_CELERY_DB=1

# Celery broker and result backend URLs (optional, auto-constructed from REDIS_HOST/REDIS_PORT/REDIS_CELERY_DB if not set)
# CELERY_BROKER_URL=redis://localhost:6379/1
# CELERY_RESULT_BACKEND=redis://localhost:6379/1

# ============================================================================
# PROCESS MONITORING CONFIGURATION
# ============================================================================
# Process Monitor automatically monitors health of Qdrant, Celery, and Redis,
# and restarts failed subprocesses with circuit breaker protection.

# Enable process monitoring (default: true)
PROCESS_MONITOR_ENABLED=true

# Health check interval in seconds (default: 30)
PROCESS_MONITOR_INTERVAL_SECONDS=30

# Maximum restart attempts before circuit breaker opens (default: 3)
PROCESS_MONITOR_MAX_RESTARTS=3

# Time window for restart count in seconds (default: 300 = 5 minutes)
PROCESS_MONITOR_RESTART_WINDOW_SECONDS=300

# Enable circuit breaker to prevent restart loops (default: true)
PROCESS_MONITOR_CIRCUIT_BREAKER_ENABLED=true

# Enable SMS alerts for critical failures (default: true)
PROCESS_MONITOR_SMS_ALERTS_ENABLED=true

# SMS alert cooldown period in seconds (default: 600 = 10 minutes)
# Prevents spam - max 1 SMS per service per cooldown period
PROCESS_MONITOR_SMS_ALERT_COOLDOWN_SECONDS=600

# ============================================================================
# HEALTH MONITORING CONFIGURATION
# ============================================================================
# Health Monitor periodically checks /health/all endpoint and sends SMS alerts
# to admin phones when server health issues are detected.

# Enable health monitoring (default: true)
HEALTH_MONITOR_ENABLED=true

# Health check interval in seconds (default: 900 = 15 minutes)
HEALTH_MONITOR_INTERVAL_SECONDS=900

# SMS alert cooldown period in seconds (default: 1800 = 30 minutes)
# Prevents alert spam if health check keeps failing
HEALTH_MONITOR_SMS_ALERT_COOLDOWN_SECONDS=1800

# Number of consecutive failures before sending alert (default: 1)
# Set to 2+ to reduce false positives from transient failures
HEALTH_MONITOR_FAILURE_THRESHOLD=1

# Health check HTTP timeout in seconds (default: 30)
HEALTH_MONITOR_TIMEOUT_SECONDS=30

# ============================================================================
# CRITICAL ALERT CONFIGURATION
# ============================================================================
# Critical Alert Service sends SMS alerts for critical application errors
# Ensures only ONE alert per critical error scenario (no spam)

# Enable critical alerting (default: true)
CRITICAL_ALERT_ENABLED=true

# Cooldown period in seconds for runtime critical errors (default: 1800 = 30 minutes)
# Prevents duplicate alerts for the same error
CRITICAL_ALERT_COOLDOWN_SECONDS=1800

# Cooldown period in seconds for unhandled exceptions (default: 3600 = 1 hour)
# Longer cooldown to prevent spam from repeated crashes
CRITICAL_ALERT_EXCEPTION_COOLDOWN_SECONDS=3600

# ============================================================================
# KNOWLEDGE SPACE (RAG) CONFIGURATION - REQUIRED
# ============================================================================
# Vector Database: Qdrant (REQUIRED)
# Qdrant server is REQUIRED for Knowledge Space features.
# Application will exit if Qdrant is not available.
#
# Install Qdrant: bash scripts/install_qdrant.sh
# Default QDRANT_HOST (change if using remote Qdrant server):
# Alternative: Use QDRANT_URL for full URL format (e.g., http://localhost:6333)
QDRANT_HOST=localhost:6333
# QDRANT_URL=http://localhost:6333

# Embedded mode storage (used when QDRANT_HOST is not set)
QDRANT_PERSIST_DIR=./storage/qdrant
QDRANT_COLLECTION_PREFIX=user_
QDRANT_COMPRESSION=SQ8

# Knowledge Space Storage
KNOWLEDGE_STORAGE_DIR=./storage/knowledge_documents
MAX_DOCUMENTS_PER_USER=5
MAX_FILE_SIZE=10485760
MAX_STORAGE_PER_USER=52428800
MAX_CHUNKS_PER_USER=1000

# Embedding Configuration
DASHSCOPE_EMBEDDING_MODEL=text-embedding-v4
DASHSCOPE_RERANK_MODEL=qwen3-rerank
EMBEDDING_BATCH_SIZE=50

# Chunking Configuration
# Options: semchunk (default, fast), mindchunk (LLM-based, semantic)
CHUNKING_ENGINE=semchunk

# Retrieval Configuration
DEFAULT_RETRIEVAL_METHOD=hybrid
HYBRID_VECTOR_WEIGHT=0.5
HYBRID_KEYWORD_WEIGHT=0.5
RERANKING_MODE=reranking_model
RERANK_SCORE_THRESHOLD=0.5
RETRIEVAL_PARALLEL_WORKERS=2

# Chunking Configuration
CHUNK_SIZE=500
CHUNK_OVERLAP=50

# ============================================================================
# EXTERNAL SERVICES CONFIGURATION
# ============================================================================
WECHAT_QR_IMAGE=
